{"train/loss": 0.0232, "train/learning_rate": 0.0, "train/rewards/chosen": -0.9857802391052246, "train/rewards/rejected": -9.867108345031738, "train/rewards/accuracies": 1.0, "train/rewards/margins": 8.881326675415039, "train/logps/rejected": -248.51634216308594, "train/logps/chosen": -150.793701171875, "train/logits/rejected": -0.3951336443424225, "train/logits/chosen": -0.3414818346500397, "train/epoch": 0.9992144540455616, "train/global_step": 795, "_timestamp": 1717907818.889204, "_runtime": 12665.754436969757, "_step": 802, "eval/loss": 0.0039458125829696655, "eval/runtime": 51.7491, "eval/samples_per_second": 2.493, "eval/steps_per_second": 1.256, "eval/rewards/chosen": -0.8877253532409668, "eval/rewards/rejected": -11.325450897216797, "eval/rewards/accuracies": 1.0, "eval/rewards/margins": 10.437726974487305, "eval/logps/rejected": -286.8272705078125, "eval/logps/chosen": -180.1938018798828, "eval/logits/rejected": -0.685943603515625, "eval/logits/chosen": -0.6644843220710754, "train_runtime": 12631.4247, "train_samples_per_second": 1.008, "train_steps_per_second": 0.063, "total_flos": 0.0, "train_loss": 0.04476163756393728, "_wandb": {"runtime": 12752}}
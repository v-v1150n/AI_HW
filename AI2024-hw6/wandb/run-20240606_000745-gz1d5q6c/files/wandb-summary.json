{"train/loss": 0.0004, "train/learning_rate": 0.0, "train/rewards/chosen": -0.7521376609802246, "train/rewards/rejected": -12.357880592346191, "train/rewards/accuracies": 1.0, "train/rewards/margins": 11.605743408203125, "train/logps/rejected": -300.3883056640625, "train/logps/chosen": -182.37628173828125, "train/logits/rejected": -2.8973734378814697, "train/logits/chosen": -2.609687566757202, "train/epoch": 0.9992144540455616, "train/global_step": 795, "_timestamp": 1717615836.375993, "_runtime": 12171.347645044327, "_step": 802, "eval/loss": 0.008337181061506271, "eval/runtime": 54.3295, "eval/samples_per_second": 2.374, "eval/steps_per_second": 1.196, "eval/rewards/chosen": -1.0292227268218994, "eval/rewards/rejected": -11.72834300994873, "eval/rewards/accuracies": 1.0, "eval/rewards/margins": 10.69912052154541, "eval/logps/rejected": -338.9008483886719, "eval/logps/chosen": -233.73231506347656, "eval/logits/rejected": -3.0424835681915283, "eval/logits/chosen": -3.0137131214141846, "train_runtime": 12097.5638, "train_samples_per_second": 1.052, "train_steps_per_second": 0.066, "total_flos": 0.0, "train_loss": 0.03377135121597274, "_wandb": {"runtime": 12269}}
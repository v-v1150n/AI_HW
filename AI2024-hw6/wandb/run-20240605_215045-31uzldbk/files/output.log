
Using cuda device
==((====))==  Unsloth: Fast Mistral patching release 2024.5
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.528 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth








































































model.safetensors: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.14G/4.14G [02:25<00:00, 28.4MB/s]
generation_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 111/111 [00:00<00:00, 253kB/s]
tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 137k/137k [00:00<00:00, 910kB/s]
tokenizer.model: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 587k/587k [00:00<00:00, 38.6MB/s]
special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 560/560 [00:00<00:00, 1.23MB/s]
tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.96M/1.96M [00:00<00:00, 2.27MB/s]
Traceback (most recent call last):
  File "/home/vv1150n/python_file/AI2024-hw6/main.py", line 80, in <module>
    DPO.DPO_train(args, output_dir)
  File "/home/vv1150n/python_file/AI2024-hw6/DPO.py", line 49, in DPO_train
    model = FastLanguageModel.get_peft_model(model, use_lora=True)
  File "/home/vv1150n/miniconda3/envs/ai_hw6/lib/python3.10/site-packages/unsloth/models/llama.py", line 1589, in get_peft_model
    lora_config = LoraConfig(**arguments)
TypeError: LoraConfig.__init__() got an unexpected keyword argument 'use_lora'
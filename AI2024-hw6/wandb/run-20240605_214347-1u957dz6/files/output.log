
Using cuda device
==((====))==  Unsloth: Fast Mistral patching release 2024.5
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.528 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.15k/1.15k [00:00<00:00, 2.71MB/s]
Traceback (most recent call last):
  File "/home/vv1150n/python_file/AI2024-hw6/main.py", line 80, in <module>
    DPO.DPO_train(args, output_dir)
  File "/home/vv1150n/python_file/AI2024-hw6/DPO.py", line 39, in DPO_train
    model, tokenizer = FastLanguageModel.from_pretrained(
  File "/home/vv1150n/miniconda3/envs/ai_hw6/lib/python3.10/site-packages/unsloth/models/loader.py", line 142, in from_pretrained
    model, tokenizer = dispatch_model.from_pretrained(
  File "/home/vv1150n/miniconda3/envs/ai_hw6/lib/python3.10/site-packages/unsloth/models/mistral.py", line 366, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
TypeError: transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained() got multiple values for keyword argument 'torch_dtype'
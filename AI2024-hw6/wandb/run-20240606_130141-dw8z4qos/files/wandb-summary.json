{"train/loss": 0.0307, "train/learning_rate": 0.0, "train/rewards/chosen": -0.7421973347663879, "train/rewards/rejected": -9.12680721282959, "train/rewards/accuracies": 1.0, "train/rewards/margins": 8.38460922241211, "train/logps/rejected": -273.2586975097656, "train/logps/chosen": -136.6582794189453, "train/logits/rejected": -0.8006467223167419, "train/logits/chosen": -0.48418498039245605, "train/epoch": 0.9992144540455616, "train/global_step": 795, "_timestamp": 1717662341.8625717, "_runtime": 12240.169497728348, "_step": 802, "eval/loss": 0.015780219808220863, "eval/runtime": 52.9278, "eval/samples_per_second": 2.437, "eval/steps_per_second": 1.228, "eval/rewards/chosen": -1.114827036857605, "eval/rewards/rejected": -9.383720397949219, "eval/rewards/accuracies": 0.9923076629638672, "eval/rewards/margins": 8.268892288208008, "eval/logps/rejected": -315.1628112792969, "eval/logps/chosen": -195.66036987304688, "eval/logits/rejected": -0.9460839033126831, "eval/logits/chosen": -0.8567714691162109, "train_runtime": 12205.4009, "train_samples_per_second": 1.043, "train_steps_per_second": 0.065, "total_flos": 0.0, "train_loss": 0.05836808191752482, "_wandb": {"runtime": 12242}}
{"train/loss": 0.1044, "train/learning_rate": 0.0, "train/rewards/chosen": -1.157527208328247, "train/rewards/rejected": -11.726785659790039, "train/rewards/accuracies": 0.9375, "train/rewards/margins": 10.569257736206055, "train/logps/rejected": -281.9756164550781, "train/logps/chosen": -197.72071838378906, "train/logits/rejected": -0.30420204997062683, "train/logits/chosen": -0.1927184909582138, "train/epoch": 0.9992144540455616, "train/global_step": 795, "_timestamp": 1717699109.0197482, "_runtime": 12733.985245227814, "_step": 802, "eval/loss": 0.01397600769996643, "eval/runtime": 55.7987, "eval/samples_per_second": 2.312, "eval/steps_per_second": 1.165, "eval/rewards/chosen": -0.8729668855667114, "eval/rewards/rejected": -11.080510139465332, "eval/rewards/accuracies": 1.0, "eval/rewards/margins": 10.207544326782227, "eval/logps/rejected": -291.0002746582031, "eval/logps/chosen": -186.5777130126953, "eval/logits/rejected": -0.6652658581733704, "eval/logits/chosen": -0.6572334170341492, "train_runtime": 12197.3163, "train_samples_per_second": 1.044, "train_steps_per_second": 0.065, "total_flos": 0.0, "train_loss": 0.046312090515235216, "_wandb": {"runtime": 12818}}